---
title: 第六周 Machine learning system design
date: 2021-01-10 17:01:03
tags: 吴恩达机器学习
---

### 一. Evaluating a learning algorithm

#### 1. Deciding What to Try Next
介绍了怎么debug一个算法，要考虑哪些方面

#### 2. Evaluating a Hypothesis
介绍了如何判断一个算法（假设）好还是坏

#### 3. Model Selection and Train/Validation/Test Sets
把数据集分成3部分，training, Cross validation, test

### 二. Bias vs. Variance

#### 1. Diagnosing Bias vs. Variance
- We need to distinguish whether bias or variance is the problem contributing to bad predictions.
- High bias is underfitting and high variance is overfitting. Ideally, we need to find a golden mean between these two.

#### 2. Regularization and Bias/Variance
- Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24});
- Create a set of models with different degrees or any other variants.
- Iterate through the \lambdaλs and for each \lambdaλ go through all the models to learn some \ThetaΘ.
- Compute the cross validation error using the learned Θ (computed with λ) on the J_{CV}(\Theta)J CV(Θ) without regularization or λ = 0.
- Select the best combo that produces the lowest error on the cross validation set.
- Using the best combo Θ and λ, apply it on J_{test}(\Theta)J test(Θ) to see if it has a good generalization of the problem.

#### 3. Learning Curves
Bias和Variance情况下分别讨论training set数据量对结果的影响

#### 4. Deciding What to Do Next Revisited

### 三. Building a spam classifier

#### 1. Prioritizing What to Work On
- Collect lots of data (for example "honeypot" project but doesn't always work)
- Develop sophisticated features (for example: using email header data in spam emails)
- Develop algorithms to process your input in different ways (recognizing misspellings in spam).

#### 2. Error Analysis

### 四. Handling skewed data

#### 1. Error Metrics for Skewed Classes

#### 2. Trading Off Precision and Recall
