---
title: 第四周 Neural Networks:Representation
date: 2021-01-07 16:20:26
tags: 吴恩达机器学习
---

### 一. Motivations

#### 1. Non-linear hypotheses
通过之前的学习我们知道了线性回归算法和逻辑回归算法，但是面对大量特征的时候这些算法的负荷太大了（用图像识别，车识别举了例子），我们需要一个更“屌”的算法来帮助实现大量特征存在的情况。

#### 2. Neurons and the Brain
这里介绍了几个大脑强大学习能力，我们就是想研究像大脑这么牛逼的算法——这也是神经网络的由来。

### 二. Neural Networks(神经网络)

#### 1. Model Representation I
这里介绍了神经网络的表示，注意：我们为每一层都增加一个偏差单位（bias unit）。
https://www.coursera.org/learn/machine-learning/supplement/Bln5m/model-representation-i

#### 2. Model Representation II
到这里已经有一点懵逼了，重新学一下之后~

### 三. Applications

#### 1. Examples and Intuitions I
神经网络中，单层神经元（无中间层）的计算可以用来表示逻辑运算，比如逻辑与（AND）、逻辑或（OR）。

#### 2. Examples and Intuitions II
为了用神经元“表示”不同的运算符我们选择不同的权重，可以利用神经元来组合成更为复杂的神经网络以实现更复杂的运算，也能得到更加厉害的特征值，这就是神经网络nb的地方。

#### 3. Multiclass Classification
https://www.coursera.org/learn/machine-learning/supplement/xSUml/multiclass-classification

